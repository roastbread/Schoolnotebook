1.The paper seeks to find a way to combine a laser range finder and monocular camera to achieve contionous localization using geometric features. They manage to achieve an accuracy in the centimeter range.
2.The camera captures vertical lines and the laser range finder captures horizontal lines.
3.It is important that with multiple sensors the fusing is sequential so thar position estimations by one sensor is not overwritten by another.
4.the five steps are State prediction, Observation, Measurement prediction, Matching and Estimation. State prediction predicts the next state and its covariance given the previous state, Observation provides the range and angle data from the sensors and their covariance, Measurement prediction uses the observation data to estimate a state of the robot, matching uses the kalman filter to combine the predictions from the odometry and sensors, Estimation provides the new state of the robot with its covariance. 
5.If the matching step returns a bad result the robot will get irreversibly lost
6.The sensor redings are validated so that outliers, bad readings  and noise can be filtered. If several features passes the validation the one with smallest Mahalanobis distance is chosen. If the validation region is large letting several features through incorrect pairings are likely to occur. The parameters in the validation are predictions and observations, represented by Z_1 and ·∫ê_1. Mahalanobis distance is better since it calculates the distance between a point and a distribution, which we have.
7. In an on the fly navigation system it is highly required that obserrvations, predictions and estimation of all involved sensors has to be maintained and related to the present. this is done by assigning timestamos to all sensory inputs. timestamps are delivered by odometry which continuosly updates the robots position and uncertainty according to equation 2 and 3 in the article. Each update recieves a timestamp and is written to a circle buffer.
8. Due to the vision sensor beiong blocked cased two problems to the localization system. First a blocked sensor cannot contibute to the localization update. Second to avoid these obstacles the robot typically turns with a higher angular velocity which in combination with the timestamp uncertainties and the low feature discriminance is likely to produce false matches.

